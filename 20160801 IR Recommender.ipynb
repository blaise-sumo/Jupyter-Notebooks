{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import pairwise_distances, cosine_similarity\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import input data\n",
    "df_spend = pd.read_csv('C:\\\\notbackedup\\\\recommender\\\\IR\\\\20160724 sample 100k 3plus.txt', delimiter='|')\n",
    "\n",
    "# make the rowindex to be the customer number\n",
    "df_spend = df_spend.set_index('CUST_ID_SRC_CUST_NO')\n",
    "\n",
    "# drop irrelevant columns \n",
    "df_spend.drop(['AGE_IN_YRS','GNDR_CD_SRC','A_SPEND_CLOTHING','A_SPEND_DIGITAL','A_SPEND_GROCERIES',\n",
    "                   'A_SPEND_MUSIC','A_SPEND_TRANSPORT','A_SPEND_TRAVEL'], axis=1, inplace=True)\n",
    "\n",
    "## create lists of column names\n",
    "l_cols_merchants = df_spend.columns\n",
    "\n",
    "n_merchants = len(df_spend.columns)\n",
    "\n",
    "# binarize the spend frequencies\n",
    "## Prepare data\n",
    "# convert merchant counts to binary flags\n",
    "def binarise(x):\n",
    "    if x>0: return 1\n",
    "    else: return 0\n",
    "    \n",
    "df_spend = df_spend.applymap(binarise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_spend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define helper function(s)\n",
    "\n",
    "# function to return index of top N values from a Numpy array\n",
    "def topindexes(a,N): return np.argsort(a)[::-1][:N] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks\n",
    "\n",
    "1. Recommend merchants at random\n",
    "2. Recommend merchants in descending order of popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function that generates recommendations using random approach\n",
    "def f_benchmark_random(ay_test):\n",
    "\n",
    "    return np.random.rand(ay_test.shape[0],ay_test.shape[1]).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function that generates recommendations using popularity approach\n",
    "def f_benchmark_popularity(ay_train, ay_test):\n",
    "    # create table with frequency count of each merchant in train dataset\n",
    "    k_freq_merchants = ay_train.sum(axis=0)\n",
    "\n",
    "    # use frequencies as recommendations for each test data record\n",
    "    recmatrix = np.tile(k_freq_merchants, ay_test.shape[0]).reshape(ay_test.shape[0],n_merchants)\n",
    "\n",
    "    return recmatrix.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### # Run 5-fold x-validation for benchmarks and measure accuracy\n",
    "\n",
    "# prepare empty lists to save results\n",
    "l_results_benchmark_random = []\n",
    "l_results_benchmark_popularity = []\n",
    "\n",
    "# run 5-fold xvalidation and collate test statistics\n",
    "k_fold = KFold(len(df_spend), 5, random_state = 1)\n",
    "\n",
    "for k, (train, test) in enumerate(k_fold):\n",
    "    print \"Processing fold\", k, \"...\"\n",
    "    \n",
    "    # convert dataframes to numpy arrays (for speed)\n",
    "    ay_train = np.array(df_spend.iloc[train])\n",
    "    ay_test = np.array(df_spend.iloc[test]) \n",
    "\n",
    "    # mask one randomly selected merchant from each record in test\n",
    "    masklist = []\n",
    "    for i in ay_test:\n",
    "        indexnonzero = np.flatnonzero(i)\n",
    "        # select one at random and add to a list of indices\n",
    "        indexselect = np.random.choice(indexnonzero)\n",
    "        masklist.append(indexselect)\n",
    "\n",
    "    # mask those merchant entries with 0's\n",
    "    ay_test = ay_test.copy()\n",
    "    ay_test[range(ay_test.shape[0]),masklist]=0  \n",
    "\n",
    "    ##### Benchmark: random #####\n",
    "    # generate recommendations\n",
    "    recmatrix = f_benchmark_random(ay_test)\n",
    "\n",
    "    ## assess accuracy of benchmark recommendations\n",
    "    # 1. drop recommendations for merchants they already shop at\n",
    "    recmatrix[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "    # 2. In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "    top3recs = np.argsort(-recmatrix)[:,:3]   # select top 3 recs for each record\n",
    "    n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "    prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "    l_results_benchmark_random.append(prop_correct_top3)\n",
    "\n",
    "    ##### Benchmark: popularity #####\n",
    "    # generate recommendations\n",
    "    recmatrix = f_benchmark_popularity(ay_train, ay_test)\n",
    "\n",
    "    ## assess accuracy of benchmark recommendations\n",
    "    # 1. drop recommendations for merchants they already shop at\n",
    "    recmatrix[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "    # 2. In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "    top3recs = np.argsort(-recmatrix)[:,:3]   # select top 3 recs for each record\n",
    "    n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "    prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "    l_results_benchmark_popularity.append(prop_correct_top3)\n",
    "    \n",
    "    \n",
    "## Print results    \n",
    "print \"Overall results: prop. masked merchants in top 3 recommendations:\"\n",
    "print \"Benchmark random: \", mean(l_results_benchmark_random)\n",
    "print \"Benchmark popularity: \", mean(l_results_benchmark_popularity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collaborative filter function\n",
    "# This calculates recommendatoins using both summed AND averaged similiarities\n",
    "# and returns a matrix for each one\n",
    "\n",
    "def f_recommender(ay_train, ay_test, n_neighbours):\n",
    "\n",
    "    ## calculate similarity matrix using Jaccard distance\n",
    "    simmatrix = 1 - pairwise_distances(ay_train, ay_test, metric='jaccard')  \n",
    "    \n",
    "    # add a tiny random number to all values so that numpy can get a full k-sized neighbourhood\n",
    "    simmatrix = simmatrix+np.random.random()/10000\n",
    "\n",
    "    ## limit to recommendations from N nearest neighbours\n",
    "    for i in range(simmatrix.shape[1]):    \n",
    "        recs = simmatrix.T[i]\n",
    "        indices = np.argpartition(-recs, n_neighbours)[:n_neighbours]\n",
    "        mask = np.ones(recs.size,dtype=bool) \n",
    "        mask[indices] = False\n",
    "        simmatrix.T[i][mask] = 0\n",
    "\n",
    "    ## generate recommendations for SUM\n",
    "    # weighted sum of merchant prensence/absence * similarity score\n",
    "    recmatrix = np.dot(simmatrix.T, ay_train)\n",
    "    \n",
    "    # average ONLY across neighbourhood\n",
    "    # to get count of merchants in neighbourhood\n",
    "    # 1. convert simmatrix to boolean flags = flags only their k neighbours\n",
    "    # 2. take dot product with ay_train\n",
    "    simmatrix_bool = simmatrix.copy()\n",
    "    simmatrix_bool[simmatrix>0]=1\n",
    "    denominator = np.dot(simmatrix_bool.T, ay_train)\n",
    "\n",
    "    recmatrix_avg = np.true_divide(recmatrix, denominator )\n",
    "\n",
    "    # return recommendation scores for all test customers, for all merchants\n",
    "    return recmatrix.astype(float), recmatrix_avg.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fold 0 ...\n",
      "Processing fold 1 ...\n",
      "Processing fold 2 ...\n",
      "Processing fold 3 ...\n",
      "Processing fold 4 ...\n",
      "Overall results: prop. masked merchants in top 3 recommendations:\n",
      "Benchmark random:  0.33301\n",
      "Benchmark popularity:  0.00341\n"
     ]
    }
   ],
   "source": [
    "# train-test implementation\n",
    "\n",
    "# set size of neighbourhood for collaborative filter\n",
    "n_neighbourhood = 500\n",
    "\n",
    "# prepare empty lists to save results\n",
    "l_results_sum = []\n",
    "l_results_avg = []\n",
    "\n",
    "# run 5-fold xvalidation and collate test statistics\n",
    "k_fold = KFold(len(df_spend), 5, random_state = 1)\n",
    "\n",
    "for k, (train, test) in enumerate(k_fold):\n",
    "    print \"Processing fold\", k, \"...\"\n",
    "    \n",
    "    # convert dataframes to numpy arrays (for speed)\n",
    "    ay_train = np.array(df_spend.iloc[train]) #df_train)\n",
    "    ay_test = np.array(df_spend.iloc[test])  # df_test)\n",
    "\n",
    "    # mask one randomly selected merchant from each record in test\n",
    "    masklist = []\n",
    "    for i in ay_test:\n",
    "        indexnonzero = np.flatnonzero(i)\n",
    "        # select one at random and add to a list of indices\n",
    "        indexselect = np.random.choice(indexnonzero)\n",
    "        masklist.append(indexselect)\n",
    "\n",
    "    # mask those merchant entries with 0's\n",
    "    ay_test = ay_test.copy()\n",
    "    ay_test[range(ay_test.shape[0]),masklist]=0  \n",
    "\n",
    "\n",
    "    # generate recommendations for SUM and AVERAGE\n",
    "    recmatrix_sum, recmatrix_avg = f_recommender(ay_train, ay_test, n_neighbourhood)\n",
    "\n",
    "    ## assess accuracy of filter recommendations\n",
    "    # 1. drop recommendations for merchants they already shop at\n",
    "    recmatrix_sum[numpy.where(ay_test==1)]=np.nan\n",
    "    recmatrix_avg[numpy.where(ay_test==1)]=np.nan\n",
    "  \n",
    "    ## Assess accuracy of both sets of recommendations\n",
    "    # 1. for SUM: In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "    top3recs = np.argsort(-recmatrix_sum)[:,:3]   # select top 3 recs for each record\n",
    "    n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "    prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "    l_results_sum.append(prop_correct_top3)\n",
    "\n",
    "    # 2. for AVG: In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "    top3recs = np.argsort(-recmatrix_avg)[:,:3]   # select top 3 recs for each record\n",
    "    n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "    prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "    l_results_avg.append(prop_correct_top3)\n",
    "\n",
    "## Print results    \n",
    "print \"Overall results: prop. masked merchants in top 3 recommendations:\"\n",
    "print \"Benchmark random: \", mean(l_results_sum)\n",
    "print \"Benchmark popularity: \", mean(l_results_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "500\n",
    "\n",
    "Benchmark random:  0.33301\n",
    "Benchmark popularity:  0.00341\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charts and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# % of customers at each merhcant\n",
    "pd.set_option('display.max_rows', 500)\n",
    "print df_spend.describe().ix[1]  # just means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Distributions of merchants and of recommendations\n",
    "# Compare distributions of \n",
    "# [1] merchant penetration of overall sample\n",
    "# [2] merchants in sum method recommendations (k=100)\n",
    "# [3] merchants in average method recommendations (k=20000)\n",
    "\n",
    "# randomly split 80-20% into two datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "ay_train, ay_test = train_test_split(df_spend, test_size=0.2, random_state=1)\n",
    "\n",
    "## raw frequency of merchants in overall sample\n",
    "merch_count = pd.DataFrame(df_spend.sum())    \n",
    "\n",
    "## sum, k100\n",
    "# generate recommendations \n",
    "recmatrix_sum, ignore = f_recommender(ay_train, ay_test, 100)\n",
    "recmatrix_sum[numpy.where(ay_test==1)]=np.nan\n",
    "top3recs_sum = np.argsort(-recmatrix_sum)[:,:3]   # select top 3 recs for each record\n",
    "\n",
    "## avg, k=20k\n",
    "ignore, recmatrix_avg = f_recommender(ay_train, ay_test, 20000)\n",
    "recmatrix_avg[numpy.where(ay_test==1)]=np.nan\n",
    "top3recs_avg = np.argsort(-recmatrix_avg)[:,:3]   # select top 3 recs for each record\n",
    "\n",
    "### Combine all into a pandas dataframe\n",
    "a = array(merch_count.index[top3recs_sum.flatten()])\n",
    "unique, counts = numpy.unique(a, return_counts=True)\n",
    "b = dict(zip(unique, counts))\n",
    "c = pd.DataFrame.from_dict(b,orient='index')\n",
    "\n",
    "a = array(merch_count.index[top3recs_avg.flatten()])\n",
    "unique, counts = numpy.unique(a, return_counts=True)\n",
    "b = dict(zip(unique, counts))\n",
    "c2 = pd.DataFrame.from_dict(b,orient='index')\n",
    "\n",
    "merch_count['series'] = 1\n",
    "c['series'] = 2\n",
    "c2['series'] = 3\n",
    "\n",
    "dfmerge = pd.concat([merch_count,c,c2], axis=0)\n",
    "dfmerge.columns = ['k','series']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export for Tableau\n",
    "dfmerge.to_csv('C:\\\\notbackedup\\\\recommender\\\\IR\\\\plot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generate bespoke recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input merchants:  ['F_TICKETMASTER']\n",
      "Top recommendations from sum approach, k=500:  ['F_BIG_W' 'F_TELSTRA' 'F_BUNNINGS' 'F_KMART' 'F_CALTEX' 'F_PAYPAL'\n",
      " 'F_MYER' 'F_TARGET' 'F_MCDONALDS' 'F_DAN_MURPHY']\n",
      "Top recommendations from average approach, k=10:  ['F_TAB' 'F_TICKETEK' 'F_QANTAS' 'F_BIG_W' 'F_JETSTAR' 'F_VILLAGE_CINEMAS'\n",
      " 'F_BUNNINGS' 'F_TELSTRA' 'F_OPTUS' 'F_DAN_MURPHY']\n",
      "Top recommendations from average approach, k=20k:  ['F_TICKETEK' 'F_AGODA_COM' 'F_WOTIF' 'F_KOBO' 'F_LASTMINUTE_COM'\n",
      " 'F_LITENEASY' 'F_BOOKDEPOSITORY' 'F_ARBONNE' 'F_GROUPON' 'F_SPOTIFY']\n"
     ]
    }
   ],
   "source": [
    "# Specify merchants which hypothetical customer shops at\n",
    "#list_merchant_input = ['F_WOTIF','F_QANTAS','F_AIRBNB'] \n",
    "#list_merchant_input = ['F_NETFLIX'] \n",
    "#list_merchant_input = ['F_RED_ROOSTER']\n",
    "#list_merchant_input = ['F_BABY_BUNTING','F_PUMPKIN_PATCH'] \n",
    "list_merchant_input = ['F_TICKETMASTER'] \n",
    "\n",
    "print \"Input merchants: \", list_merchant_input\n",
    "\n",
    "\n",
    "## Create a dummy record to use as test dataset\n",
    "tdf = df_spend.iloc[0] \n",
    "tdf = tdf * 0  # reset all values to 0\n",
    "# input some values for selected merchants\n",
    "tdf[list_merchant_input] = 1\n",
    "# duplicate so we get a matrix of two identical customers\n",
    "tdf = pd.concat([tdf, tdf], axis=1)\n",
    "ay_train = array(df_spend)\n",
    "ay_test = array(tdf).T\n",
    "\n",
    "\n",
    "## generate recommendations for three different k\n",
    "# for sum, k=500\n",
    "n_neighbourhood = 500\n",
    "recmatrix_sum, recmatrix_avg = f_recommender(ay_train, ay_test, n_neighbourhood)\n",
    "\n",
    "# drop recommendations for merchants they already shop at\n",
    "recmatrix_sum[numpy.where(matrix(ay_test)==1)]=np.nan\n",
    "recmatrix_avg[numpy.where(matrix(ay_test)==1)]=np.nan\n",
    "\n",
    "# get top 3 & print merchants\n",
    "top3recs = np.argsort(-recmatrix_sum)[:,:10]   \n",
    "print \"Top recommendations from sum approach, k=500: \", df_spend.columns[top3recs][0]\n",
    "\n",
    "\n",
    "# for average, k=10\n",
    "n_neighbourhood = 10\n",
    "recmatrix_sum, recmatrix_avg = f_recommender(ay_train, ay_test, n_neighbourhood)\n",
    "\n",
    "# drop recommendations for merchants they already shop at\n",
    "recmatrix_sum[numpy.where(matrix(ay_test)==1)]=np.nan\n",
    "recmatrix_avg[numpy.where(matrix(ay_test)==1)]=np.nan\n",
    "\n",
    "# get top 3 & print merchants\n",
    "top3recs = np.argsort(-recmatrix_avg)[:,:10]   \n",
    "print \"Top recommendations from average approach, k=10: \", df_spend.columns[top3recs][0]\n",
    "\n",
    "\n",
    "# for average, k=200k\n",
    "n_neighbourhood = 20000\n",
    "recmatrix_sum, recmatrix_avg = f_recommender(ay_train, ay_test, n_neighbourhood)\n",
    "\n",
    "# drop recommendations for merchants they already shop at\n",
    "recmatrix_sum[numpy.where(matrix(ay_test)==1)]=np.nan\n",
    "recmatrix_avg[numpy.where(matrix(ay_test)==1)]=np.nan\n",
    "\n",
    "# get top 3 & print merchants\n",
    "top3recs = np.argsort(-recmatrix_avg)[:,:10]   \n",
    "print \"Top recommendations from average approach, k=20k: \", df_spend.columns[top3recs][0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merchant correlation matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## calculate similarity matrix using Jaccard distance\n",
    "simmatrix = 1 - pairwise_distances(df_spend.T, df_spend.T, metric='jaccard')  \n",
    "\n",
    "sdf = pd.DataFrame(simmatrix, index=df_spend.columns, columns=df_spend.columns)\n",
    "sdf = sdf.fillna(0)\n",
    "\n",
    "plotdf = sdf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set same-merchant intersections to 0 so not shown\n",
    "# this is all intersections where rownum = column num\n",
    "for i in range(len(plotdf)):\n",
    "    plotdf.iat[i,i]=0\n",
    "corrdf_plot = plotdf \n",
    "#corrdf_plot[corrdf_plot>0.4]=0.4\n",
    "\n",
    "# Adjust so that each row is proportional to biggest correlation\n",
    "#corrdf_plot = (plotdf.divide(plotdf.max(axis=0)).fillna(0))\n",
    "#corrdf_plot.fillna(0)\n",
    "\n",
    "# Plot it out\n",
    "fig, ax = plt.subplots()\n",
    "heatmap = ax.pcolor(corrdf_plot, cmap=plt.cm.Blues, alpha=0.8)#, vmax=0.3)\n",
    "\n",
    "# Format\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(30, 30)\n",
    "\n",
    "# turn off the frame\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# put the major ticks at the middle of each cell\n",
    "ax.set_yticks(np.arange(corrdf_plot.shape[0]) + 0.5, minor=False)\n",
    "ax.set_xticks(np.arange(corrdf_plot.shape[1]) + 0.5, minor=False)\n",
    "\n",
    "# want a more natural, table-like display\n",
    "ax.invert_yaxis()\n",
    "ax.xaxis.tick_top()\n",
    "\n",
    "# Set the labels\n",
    "\n",
    "# label source:https://en.wikipedia.org/wiki/Basketball_statistics\n",
    "labels = sdf.index\n",
    "\n",
    "# note I could have used nba_sort.columns but made \"labels\" instead\n",
    "ax.set_xticklabels(labels, minor=False)\n",
    "ax.set_yticklabels(corrdf_plot.index, minor=False)\n",
    "\n",
    "# rotate the\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "ax.grid(False)\n",
    "\n",
    "# Turn off all the ticks\n",
    "ax = plt.gca()\n",
    "\n",
    "for t in ax.xaxis.get_major_ticks():\n",
    "    t.tick1On = False\n",
    "    t.tick2On = False\n",
    "for t in ax.yaxis.get_major_ticks():\n",
    "    t.tick1On = False\n",
    "    t.tick2On = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This with log scale\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# set same-merchant intersections to 0 so not shown\n",
    "# this is all intersections where rownum = column num\n",
    "for i in range(len(plotdf)):\n",
    "    plotdf.iat[i,i]=0\n",
    "corrdf_plot = plotdf + 0.1  # for log scale\n",
    "# Adjust so that each row is proportional to biggest correlation\n",
    "#corrdf_plot = (plotdf.divide(plotdf.max(axis=0)).fillna(0))\n",
    "#corrdf_plot.fillna(0)\n",
    "\n",
    "# Plot it out\n",
    "fig, ax = plt.subplots()\n",
    "heatmap = ax.pcolor(corrdf_plot, norm=LogNorm(vmin=corrdf_plot.values.min(), vmax=corrdf_plot.values.max()), cmap=plt.cm.Blues, alpha=0.8)\n",
    "\n",
    "#fig.colorbar()\n",
    "#plt.pcolor(X, Y, Z1, norm=LogNorm(vmin=Z1.min(), vmax=Z1.max()), cmap='PuBu_r')\n",
    "\n",
    "\n",
    "# Format\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(30, 30)\n",
    "\n",
    "# turn off the frame\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# put the major ticks at the middle of each cell\n",
    "ax.set_yticks(np.arange(corrdf_plot.shape[0]) + 0.5, minor=False)\n",
    "ax.set_xticks(np.arange(corrdf_plot.shape[1]) + 0.5, minor=False)\n",
    "\n",
    "# want a more natural, table-like display\n",
    "ax.invert_yaxis()\n",
    "ax.xaxis.tick_top()\n",
    "\n",
    "# Set the labels\n",
    "\n",
    "# label source:https://en.wikipedia.org/wiki/Basketball_statistics\n",
    "labels = sdf.index\n",
    "\n",
    "# note I could have used nba_sort.columns but made \"labels\" instead\n",
    "ax.set_xticklabels(labels, minor=False)\n",
    "ax.set_yticklabels(corrdf_plot.index, minor=False)\n",
    "\n",
    "# rotate the\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "ax.grid(False)\n",
    "\n",
    "# Turn off all the ticks\n",
    "ax = plt.gca()\n",
    "\n",
    "for t in ax.xaxis.get_major_ticks():\n",
    "    t.tick1On = False\n",
    "    t.tick2On = False\n",
    "for t in ax.yaxis.get_major_ticks():\n",
    "    t.tick1On = False\n",
    "    t.tick2On = False\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## THIS VERSION SCALED BY ROW\n",
    "\n",
    "\n",
    "# set same-merchant intersections to 0 so not shown\n",
    "# this is all intersections where rownum = column num\n",
    "for i in range(len(plotdf)):\n",
    "    plotdf.iat[i,i]=0\n",
    "# Adjust so that each row is proportional to biggest correlation\n",
    "corrdf_plot = (plotdf.divide(plotdf.max(axis=0)).fillna(0))\n",
    "#corrdf_plot.fillna(0)\n",
    "\n",
    "# Plot it out\n",
    "fig, ax = plt.subplots()\n",
    "heatmap = ax.pcolor(corrdf_plot, cmap=plt.cm.Blues, alpha=0.8)\n",
    "\n",
    "# Format\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(30, 30)\n",
    "\n",
    "# turn off the frame\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# put the major ticks at the middle of each cell\n",
    "ax.set_yticks(np.arange(corrdf_plot.shape[0]) + 0.5, minor=False)\n",
    "ax.set_xticks(np.arange(corrdf_plot.shape[1]) + 0.5, minor=False)\n",
    "\n",
    "# want a more natural, table-like display\n",
    "ax.invert_yaxis()\n",
    "ax.xaxis.tick_top()\n",
    "\n",
    "# Set the labels\n",
    "\n",
    "# label source:https://en.wikipedia.org/wiki/Basketball_statistics\n",
    "labels = sdf.index\n",
    "\n",
    "# note I could have used nba_sort.columns but made \"labels\" instead\n",
    "ax.set_xticklabels(labels, minor=False)\n",
    "ax.set_yticklabels(corrdf_plot.index, minor=False)\n",
    "\n",
    "# rotate the\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "ax.grid(False)\n",
    "\n",
    "# Turn off all the ticks\n",
    "ax = plt.gca()\n",
    "\n",
    "for t in ax.xaxis.get_major_ticks():\n",
    "    t.tick1On = False\n",
    "    t.tick2On = False\n",
    "for t in ax.yaxis.get_major_ticks():\n",
    "    t.tick1On = False\n",
    "    t.tick2On = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "results, 100k, jaccard\n",
    "\n",
    "k=20\n",
    "Benchmark:  0.23865 , Filter sum:  [0.28720000000000001, 0.28655000000000003, 0.28760000000000002, 0.28844999999999998, 0.29475000000000001] Filter avg:  [0.082299999999999998, 0.080100000000000005, 0.078799999999999995, 0.080149999999999999, 0.083349999999999994]\n",
    "Overall results: mean % masked merchants in top 3 recommendations:\n",
    "Benchmark:  0.23766 , Filter sum:  0.28891 , Filter sum:  0.08094\n",
    "\n",
    "k=35\n",
    "Benchmark:  0.2402 , Filter sum:  [0.30609999999999998, 0.30535000000000001, 0.30559999999999998, 0.30330000000000001, 0.30630000000000002] Filter avg:  [0.061650000000000003, 0.057099999999999998, 0.058099999999999999, 0.054899999999999997, 0.057299999999999997]\n",
    "Overall results: mean % masked merchants in top 3 recommendations:\n",
    "Benchmark:  0.23698 , Filter sum:  0.30533 , Filter sum:  0.05781\n",
    "\n",
    "\n",
    "k=50\n",
    "% masked merchants in top 3 recommendations: \n",
    "Benchmark:  0.23765 , Filter sum:  [0.3206, 0.31809999999999999, 0.31790000000000002, 0.32055, 0.32055] Filter avg:  [0.044499999999999998, 0.042549999999999998, 0.043950000000000003, 0.043200000000000002, 0.045150000000000003]\n",
    "Overall results: mean % masked merchants in top 3 recommendations:\n",
    "Benchmark:  0.23979 , Filter sum:  0.31954 , Filter sum:  0.04387\n",
    "\n",
    "\n",
    "k=100\n",
    "% masked merchants in top 3 recommendations: \n",
    "Benchmark:  0.23635 , Filter sum:  [0.32955000000000001, 0.33065, 0.33024999999999999, 0.32829999999999998, 0.3291] Filter avg:  [0.022800000000000001, 0.023949999999999999, 0.024549999999999999, 0.023099999999999999, 0.02445]\n",
    "Overall results: mean % masked merchants in top 3 recommendations:\n",
    "Benchmark:  0.23746 , Filter sum:  0.32957 , Filter sum:  0.02377\n",
    "\n",
    "\n",
    "k=500\n",
    "Benchmark:  0.2404 , Filter sum:  [0.32679999999999998, 0.33505000000000001, 0.33000000000000002, 0.33384999999999998, 0.33905000000000002] Filter avg:  [0.0033500000000000001, 0.0028, 0.0033, 0.0041999999999999997, 0.0035000000000000001]\n",
    "Overall results: mean % masked merchants in top 3 recommendations:\n",
    "Benchmark:  0.23758 , Filter sum:  0.33295 , Filter sum:  0.00343\n",
    "\n",
    "\n",
    "\n",
    "k=1000\n",
    "% masked merchants in top 3 recommendations: \n",
    "Benchmark:  0.23615 , Filter sum:  [0.32779999999999998, 0.33705000000000002, 0.3246, 0.33484999999999998, 0.33090000000000003] Filter avg:  [0.0019, 0.00175, 0.00165, 0.0020999999999999999, 0.0016000000000000001]\n",
    "Overall results: mean % masked merchants in top 3 recommendations:\n",
    "Benchmark:  0.23792 , Filter sum:  0.33104 , Filter sum:  0.0018\n",
    "\n",
    "k=5k\n",
    "Benchmark:  0.232 , Filter sum:  [0.31580000000000003, 0.32169999999999999, 0.3206, 0.32029999999999997, 0.31614999999999999] Filter avg:  [0.0032000000000000002, 0.0038500000000000001, 0.0028, 0.0041999999999999997, 0.0033]\n",
    "Overall results: mean % masked merchants in top 3 recommendations:\n",
    "Benchmark:  0.23742 , Filter sum:  0.31891 , Filter sum:  0.00347\n",
    "\n",
    "k=10k\n",
    "Benchmark:  0.23625 , Filter sum:  [0.3135, 0.31175000000000003, 0.31435000000000002, 0.32169999999999999, 0.30909999999999999] Filter avg:  [0.026249999999999999, 0.024750000000000001, 0.024500000000000001, 0.025649999999999999, 0.025100000000000001]\n",
    "Overall results: mean % masked merchants in top 3 recommendations:\n",
    "Benchmark:  0.23637 , Filter sum:  0.31408 , Filter sum:  0.02525\n",
    "\n",
    "\n",
    "k=20k\n",
    "Benchmark:  0.23755 , Filter sum:  [0.30935000000000001, 0.30299999999999999, 0.30314999999999998, 0.30259999999999998, 0.30470000000000003] Filter avg:  [0.065600000000000006, 0.073249999999999996, 0.068199999999999997, 0.071650000000000005, 0.071150000000000005]\n",
    "Overall results: mean % masked merchants in top 3 recommendations:\n",
    "Benchmark:  0.23896 , Filter sum:  0.30456 , Filter sum:  0.06997\n",
    "\n",
    "\n",
    "now do recommendations, determine if you really need 100k befpore running rest\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
