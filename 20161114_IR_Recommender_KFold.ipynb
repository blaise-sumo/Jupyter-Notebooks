{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Overnight scheme\n",
    "\n",
    "for each of 5 iterations: randomly select 25k from the 100k\n",
    "do xfold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "## Initialise\n",
    "#############################\n",
    "\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import pairwise_distances, cosine_similarity\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "\n",
    "#############################\n",
    "## Parameters\n",
    "#############################\n",
    "\n",
    "# set size of neighbourhood for collaborative filter\n",
    "n_neighbourhood = 100\n",
    "\n",
    "# set number of folds for k-Fold xvalidation\n",
    "n_folds = 5\n",
    "\n",
    "# set number of iterations of k-Fold to perform\n",
    "n_iter_kfold = 5\n",
    "\n",
    "\n",
    "#############################\n",
    "## Prepare data\n",
    "#############################\n",
    "\n",
    "# Import input data\n",
    "df_spend = pd.read_csv('C:\\\\notbackedup\\\\recommender\\\\IR\\\\20160724 sample 100k 3plus.txt', delimiter='|')\n",
    "\n",
    "# make the rowindex to be the customer number\n",
    "df_spend = df_spend.set_index('CUST_ID_SRC_CUST_NO')\n",
    "\n",
    "# drop irrelevant columns \n",
    "df_spend.drop(['AGE_IN_YRS','GNDR_CD_SRC','A_SPEND_CLOTHING','A_SPEND_DIGITAL','A_SPEND_GROCERIES',\n",
    "                   'A_SPEND_MUSIC','A_SPEND_TRANSPORT','A_SPEND_TRAVEL'], axis=1, inplace=True)\n",
    "\n",
    "## create lists of column names\n",
    "l_cols_merchants = df_spend.columns\n",
    "\n",
    "n_merchants = len(df_spend.columns)\n",
    "\n",
    "# binarize the spend frequencies\n",
    "## Prepare data\n",
    "# convert merchant counts to binary flags\n",
    "def binarise(x):\n",
    "    if x>0: return 1\n",
    "    else: return 0\n",
    "    \n",
    "df_spend = df_spend.applymap(binarise)\n",
    "\n",
    "#############################\n",
    "## Helper functions\n",
    "#############################\n",
    "\n",
    "# function to return index of top N values from a Numpy array\n",
    "def topindexes(a,N): return np.argsort(a)[::-1][:N] \n",
    "\n",
    "#################################################################\n",
    "## Functions for different methods of making recommendations\n",
    "#################################################################\n",
    "\n",
    "# Recommendations made at random\n",
    "def f_benchmark_random(ay_test):\n",
    "    return np.random.rand(ay_test.shape[0],ay_test.shape[1]).astype(float)\n",
    "\n",
    "\n",
    "# Recommendations made in descending order of merchant popularity\n",
    "def f_benchmark_popularity(ay_train, ay_test):\n",
    "    # create table with frequency count of each merchant in train dataset\n",
    "    k_freq_merchants = ay_train.sum(axis=0)\n",
    "\n",
    "    # use frequencies as recommendations for each test data record\n",
    "    recmatrix = np.tile(k_freq_merchants, ay_test.shape[0]).reshape(ay_test.shape[0],n_merchants)\n",
    "\n",
    "    return recmatrix.astype(float)\n",
    "\n",
    "\n",
    "# Recommendations using collaborative filtering\n",
    "# This calculates recommendatoins using both summed AND averaged similiarities\n",
    "# and returns a matrix for each one\n",
    "def f_recommender(ay_train, ay_test, n_neighbours):\n",
    "\n",
    "    ## calculate similarity matrix using Jaccard distance\n",
    "    simmatrix = 1 - pairwise_distances(ay_train, ay_test, metric='jaccard')  \n",
    "    \n",
    "    # add a tiny random number to all values so that numpy can get a full k-sized neighbourhood\n",
    "    simmatrix = simmatrix+np.random.random()/10000\n",
    "\n",
    "    ## limit to recommendations from N nearest neighbours\n",
    "    for i in range(simmatrix.shape[1]):    \n",
    "        recs = simmatrix.T[i]\n",
    "        indices = np.argpartition(-recs, n_neighbours)[:n_neighbours]\n",
    "        mask = np.ones(recs.size,dtype=bool) \n",
    "        mask[indices] = False\n",
    "        simmatrix.T[i][mask] = 0\n",
    "\n",
    "    ## generate recommendations for SUM\n",
    "    # weighted sum of merchant prensence/absence * similarity score\n",
    "    recmatrix = np.dot(simmatrix.T, ay_train)\n",
    "    \n",
    "    # average ONLY across neighbourhood\n",
    "    # to get count of merchants in neighbourhood\n",
    "    # 1. convert simmatrix to boolean flags = flags only their k neighbours\n",
    "    # 2. take dot product with ay_train\n",
    "    simmatrix_bool = simmatrix.copy()\n",
    "    simmatrix_bool[simmatrix>0]=1\n",
    "    denominator = np.dot(simmatrix_bool.T, ay_train)\n",
    "\n",
    "    recmatrix_avg = np.true_divide(recmatrix, denominator )\n",
    "\n",
    "    # return recommendation scores for all test customers, for all merchants\n",
    "    return recmatrix.astype(float), recmatrix_avg.astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing iteration 1 of 5 ...\n",
      "                            ... fold 1 of 5\n",
      "                            ... fold 2 of 5\n",
      "                            ... fold 3 of 5\n",
      "                            ... fold 4 of 5\n",
      "                            ... fold 5 of 5\n",
      "Processing iteration 2 of 5 ...\n",
      "                            ... fold 1 of 5\n",
      "                            ... fold 2 of 5\n",
      "                            ... fold 3 of 5\n",
      "                            ... fold 4 of 5\n",
      "                            ... fold 5 of 5\n",
      "Processing iteration 3 of 5 ...\n",
      "                            ... fold 1 of 5\n",
      "                            ... fold 2 of 5\n",
      "                            ... fold 3 of 5\n",
      "                            ... fold 4 of 5\n",
      "                            ... fold 5 of 5\n",
      "Processing iteration"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "## Run k-Fold validation to assess accuracy of recommendations\n",
    "#################################################################\n",
    "\n",
    "# prepare empty lists to save results \n",
    "l_results_benchmark_random = []\n",
    "l_results_benchmark_popularity = []\n",
    "l_results_sum = []\n",
    "l_results_avg = []\n",
    "\n",
    "# For the parameterised # of iterations...\n",
    "for n_iter in range(1, n_iter_kfold+1):\n",
    "    print \"Processing iteration\", n_iter, \"of\", n_iter_kfold, \"...\"\n",
    "\n",
    "    # ...run k-fold xvalidation and collate test statistics\n",
    "    k_fold = KFold(len(df_spend), n_folds)     # random_state = 1\n",
    "\n",
    "    for k, (train, test) in enumerate(k_fold):\n",
    "        print \"                            ... fold\", k+1, \"of\", n_folds\n",
    "\n",
    "        # convert dataframes to numpy arrays (for speed)\n",
    "        ay_train = np.array(df_spend.iloc[train]) #df_train)\n",
    "        ay_test = np.array(df_spend.iloc[test])  # df_test)\n",
    "\n",
    "        # mask one randomly selected merchant from each record in test\n",
    "        masklist = []\n",
    "        for i in ay_test:\n",
    "            indexnonzero = np.flatnonzero(i)\n",
    "            # select one at random and add to a list of indices\n",
    "            indexselect = np.random.choice(indexnonzero)\n",
    "            masklist.append(indexselect)\n",
    "\n",
    "        # mask those merchant entries with 0's\n",
    "        ay_test = ay_test.copy()\n",
    "        ay_test[range(ay_test.shape[0]),masklist]=0  \n",
    "\n",
    "\n",
    "        ##### Benchmark: random #####\n",
    "        # generate recommendations\n",
    "        recmatrix = f_benchmark_random(ay_test)\n",
    "\n",
    "        ## assess accuracy of benchmark recommendations\n",
    "        # 1. drop recommendations for merchants they already shop at\n",
    "        recmatrix[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "        # 2. In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "        top3recs = np.argsort(-recmatrix)[:,:3]   # select top 3 recs for each record\n",
    "        n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "        prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "        l_results_benchmark_random.append(prop_correct_top3)\n",
    "\n",
    "        ##### Benchmark: popularity #####\n",
    "        # generate recommendations\n",
    "        recmatrix = f_benchmark_popularity(ay_train, ay_test)\n",
    "\n",
    "        ## assess accuracy of benchmark recommendations\n",
    "        # 1. drop recommendations for merchants they already shop at\n",
    "        recmatrix[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "        # 2. In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "        top3recs = np.argsort(-recmatrix)[:,:3]   # select top 3 recs for each record\n",
    "        n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "        prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "        l_results_benchmark_popularity.append(prop_correct_top3)\n",
    "\n",
    "        ##### COLLABORATIVE FILTER #####\n",
    "        # generate recommendations for SUM and AVERAGE\n",
    "        recmatrix_sum, recmatrix_avg = f_recommender(ay_train, ay_test, n_neighbourhood)\n",
    "\n",
    "        ## assess accuracy of filter recommendations\n",
    "        # 1. drop recommendations for merchants they already shop at\n",
    "        recmatrix_sum[numpy.where(ay_test==1)]=np.nan\n",
    "        recmatrix_avg[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "        ## Assess accuracy of both sets of recommendations\n",
    "        # 1. for SUM: In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "        top3recs = np.argsort(-recmatrix_sum)[:,:3]   # select top 3 recs for each record\n",
    "        n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "        prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "        l_results_sum.append(prop_correct_top3)\n",
    "\n",
    "        # 2. for AVG: In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "        top3recs = np.argsort(-recmatrix_avg)[:,:3]   # select top 3 recs for each record\n",
    "        n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "        prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "        l_results_avg.append(prop_correct_top3)\n",
    "\n",
    "## Print results    \n",
    "print \"Overall mean results: prop. masked merchants in top 3 recommendations:\"\n",
    "print \"Benchmark random: \", mean(l_results_benchmark_random)\n",
    "print \"Benchmark popularity: \", mean(l_results_benchmark_popularity)\n",
    "print \"Collaborative filter (sum method): \", mean(l_results_sum)\n",
    "print \"Collaborative filter (avg method): \", mean(l_results_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing neigbourhood 10\n",
      "Processing iteration 1 of 5 ...\n",
      "Processing iteration 2 of 5 ...\n",
      "Processing iteration 3 of 5 ...\n",
      "Processing iteration 4 of 5 ...\n",
      "Processing iteration 5 of 5 ...\n",
      "Overall mean results: prop. masked merchants in top 3 recommendations:\n",
      "Benchmark random:  0.024056\n",
      "Benchmark popularity:  0.240616\n",
      "Collaborative filter (sum method):  0.259168\n",
      "Collaborative filter (avg method):  0.099784\n",
      "Processing neigbourhood 20\n",
      "Processing iteration 1 of 5 ...\n",
      "Processing iteration 2 of 5 ...\n",
      "Processing iteration 3 of 5 ...\n",
      "Processing iteration 4 of 5 ...\n",
      "Processing iteration 5 of 5 ...\n",
      "Overall mean results: prop. masked merchants in top 3 recommendations:\n",
      "Benchmark random:  0.02396\n",
      "Benchmark popularity:  0.237632\n",
      "Collaborative filter (sum method):  0.292624\n",
      "Collaborative filter (avg method):  0.067448\n",
      "Processing neigbourhood 35\n",
      "Processing iteration 1 of 5 ...\n",
      "Processing iteration 2 of 5 ...\n",
      "Processing iteration 3 of 5 ...\n",
      "Processing iteration 4 of 5 ...\n",
      "Processing iteration 5 of 5 ...\n",
      "Overall mean results: prop. masked merchants in top 3 recommendations:\n",
      "Benchmark random:  0.024088\n",
      "Benchmark popularity:  0.239408\n",
      "Collaborative filter (sum method):  0.307168\n",
      "Collaborative filter (avg method):  0.043712\n",
      "Processing neigbourhood 50\n",
      "Processing iteration 1 of 5 ...\n",
      "Processing iteration 2 of 5 ...\n",
      "Processing iteration 3 of 5 ...\n",
      "Processing iteration 4 of 5 ...\n",
      "Processing iteration 5 of 5 ...\n",
      "Overall mean results: prop. masked merchants in top 3 recommendations:\n",
      "Benchmark random:  0.02404\n",
      "Benchmark popularity:  0.23808\n",
      "Collaborative filter (sum method):  0.316392\n",
      "Collaborative filter (avg method):  0.032008\n",
      "Processing neigbourhood 100\n",
      "Processing iteration 1 of 5 ...\n",
      "Processing iteration 2 of 5 ...\n",
      "Processing iteration 3 of 5 ...\n",
      "Processing iteration 4 of 5 ...\n",
      "Processing iteration 5 of 5 ...\n",
      "Overall mean results: prop. masked merchants in top 3 recommendations:\n",
      "Benchmark random:  0.023512\n",
      "Benchmark popularity:  0.238344\n",
      "Collaborative filter (sum method):  0.32608\n",
      "Collaborative filter (avg method):  0.015256\n",
      "Processing neigbourhood 500\n",
      "Processing iteration 1 of 5 ...\n",
      "Processing iteration 2 of 5 ...\n",
      "Processing iteration 3 of 5 ...\n",
      "Processing iteration 4 of 5 ...\n",
      "Processing iteration 5 of 5 ...\n",
      "Overall mean results: prop. masked merchants in top 3 recommendations:\n",
      "Benchmark random:  0.02408\n",
      "Benchmark popularity:  0.237152\n",
      "Collaborative filter (sum method):  0.324128\n",
      "Collaborative filter (avg method):  0.00272\n",
      "Processing neigbourhood 1000\n",
      "Processing iteration 1 of 5 ...\n",
      "Processing iteration 2 of 5 ...\n",
      "Processing iteration 3 of 5 ...\n",
      "Processing iteration 4 of 5 ...\n",
      "Processing iteration 5 of 5 ...\n",
      "Overall mean results: prop. masked merchants in top 3 recommendations:\n",
      "Benchmark random:  0.02404\n",
      "Benchmark popularity:  0.238072\n",
      "Collaborative filter (sum method):  0.323536\n",
      "Collaborative filter (avg method):  0.002008\n",
      "Processing neigbourhood 5000\n",
      "Processing iteration 1 of 5 ...\n",
      "Processing iteration 2 of 5 ...\n",
      "Processing iteration 3 of 5 ...\n",
      "Processing iteration 4 of 5 ...\n",
      "Processing iteration 5 of 5 ...\n",
      "Overall mean results: prop. masked merchants in top 3 recommendations:\n",
      "Benchmark random:  0.023344\n",
      "Benchmark popularity:  0.23972\n",
      "Collaborative filter (sum method):  0.305912\n",
      "Collaborative filter (avg method):  0.015656\n",
      "Processing neigbourhood 10000\n",
      "Processing iteration 1 of 5 ...\n",
      "Processing iteration 2 of 5 ...\n",
      "Processing iteration 3 of 5 ...\n",
      "Processing iteration 4 of 5 ...\n",
      "Processing iteration 5 of 5 ...\n",
      "Overall mean results: prop. masked merchants in top 3 recommendations:\n",
      "Benchmark random:  0.024072\n",
      "Benchmark popularity:  0.238728\n",
      "Collaborative filter (sum method):  0.288344\n",
      "Collaborative filter (avg method):  0.044648\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## SPECIAL OVERNIGHT CODE\n",
    "\n",
    "# BACKUP DF_SPEND\n",
    "df_spend_master = df_spend.copy()\n",
    "\n",
    "list_neighbourhoods = [10,20,35,50,100,500,1000,5000,10000]\n",
    "\n",
    "for neighbourhood_value in list_neighbourhoods:\n",
    "    n_neighbourhood = neighbourhood_value\n",
    "    \n",
    "    print \"Processing neigbourhood\", neighbourhood_value\n",
    "    \n",
    "    # prepare empty lists to save results \n",
    "    l_results_benchmark_random = []\n",
    "    l_results_benchmark_popularity = []\n",
    "    l_results_sum = []\n",
    "    l_results_avg = []\n",
    "\n",
    "    # For the parameterised # of iterations...\n",
    "    for n_iter in range(1, n_iter_kfold+1):\n",
    "        print \"Processing iteration\", n_iter, \"of\", n_iter_kfold, \"...\"\n",
    "\n",
    "        df_spend = df_spend_master.sample(25000)\n",
    "\n",
    "        # ...run k-fold xvalidation and collate test statistics\n",
    "        k_fold = KFold(len(df_spend), n_folds)     # random_state = 1\n",
    "\n",
    "        for k, (train, test) in enumerate(k_fold):\n",
    "#            print \"                            ... fold\", k+1, \"of\", n_folds\n",
    "\n",
    "            # convert dataframes to numpy arrays (for speed)\n",
    "            ay_train = np.array(df_spend.iloc[train]) #df_train)\n",
    "            ay_test = np.array(df_spend.iloc[test])  # df_test)\n",
    "\n",
    "            # mask one randomly selected merchant from each record in test\n",
    "            masklist = []\n",
    "            for i in ay_test:\n",
    "                indexnonzero = np.flatnonzero(i)\n",
    "                # select one at random and add to a list of indices\n",
    "                indexselect = np.random.choice(indexnonzero)\n",
    "                masklist.append(indexselect)\n",
    "\n",
    "            # mask those merchant entries with 0's\n",
    "            ay_test = ay_test.copy()\n",
    "            ay_test[range(ay_test.shape[0]),masklist]=0  \n",
    "\n",
    "\n",
    "            ##### Benchmark: random #####\n",
    "            # generate recommendations\n",
    "            recmatrix = f_benchmark_random(ay_test)\n",
    "\n",
    "            ## assess accuracy of benchmark recommendations\n",
    "            # 1. drop recommendations for merchants they already shop at\n",
    "            recmatrix[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "            # 2. In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "            top3recs = np.argsort(-recmatrix)[:,:3]   # select top 3 recs for each record\n",
    "            n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "            prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "            l_results_benchmark_random.append(prop_correct_top3)\n",
    "\n",
    "            ##### Benchmark: popularity #####\n",
    "            # generate recommendations\n",
    "            recmatrix = f_benchmark_popularity(ay_train, ay_test)\n",
    "\n",
    "            ## assess accuracy of benchmark recommendations\n",
    "            # 1. drop recommendations for merchants they already shop at\n",
    "            recmatrix[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "            # 2. In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "            top3recs = np.argsort(-recmatrix)[:,:3]   # select top 3 recs for each record\n",
    "            n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "            prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "            l_results_benchmark_popularity.append(prop_correct_top3)\n",
    "\n",
    "            ##### COLLABORATIVE FILTER #####\n",
    "            # generate recommendations for SUM and AVERAGE\n",
    "            recmatrix_sum, recmatrix_avg = f_recommender(ay_train, ay_test, n_neighbourhood)\n",
    "\n",
    "            ## assess accuracy of filter recommendations\n",
    "            # 1. drop recommendations for merchants they already shop at\n",
    "            recmatrix_sum[numpy.where(ay_test==1)]=np.nan\n",
    "            recmatrix_avg[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "            ## Assess accuracy of both sets of recommendations\n",
    "            # 1. for SUM: In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "            top3recs = np.argsort(-recmatrix_sum)[:,:3]   # select top 3 recs for each record\n",
    "            n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "            prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "            l_results_sum.append(prop_correct_top3)\n",
    "\n",
    "            # 2. for AVG: In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "            top3recs = np.argsort(-recmatrix_avg)[:,:3]   # select top 3 recs for each record\n",
    "            n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "            prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "            l_results_avg.append(prop_correct_top3)\n",
    "\n",
    "    ## Print results    \n",
    "    print \"Overall mean results: prop. masked merchants in top 3 recommendations:\"\n",
    "    print \"Benchmark random: \", mean(l_results_benchmark_random)\n",
    "    print \"Benchmark popularity: \", mean(l_results_benchmark_popularity)\n",
    "    print \"Collaborative filter (sum method): \", mean(l_results_sum)\n",
    "    print \"Collaborative filter (avg method): \", mean(l_results_avg)\n",
    "\n",
    "    text_file = open(\"Output.txt\", \"a\")\n",
    "\n",
    "    text_file.write(\"neighourhood: \")\n",
    "    text_file.write(str(n_neighbourhood))\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.write(\"random: \")\n",
    "    text_file.write(str(mean(l_results_benchmark_random)))\n",
    "    text_file.write(\"  -- SD:  \")\n",
    "    text_file.write(str(std(l_results_benchmark_random)))\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.write(\"popularity: \")\n",
    "    text_file.write(str(mean(l_results_benchmark_popularity)))\n",
    "    text_file.write(\"  -- SD:  \")\n",
    "    text_file.write(str(std(l_results_benchmark_popularity)))\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.write(\"Collaborative filter (sum method): \")\n",
    "    text_file.write(str(mean(l_results_sum)))\n",
    "    text_file.write(\"  -- SD:  \")\n",
    "    text_file.write(str(std(l_results_sum)))\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.write(\"Collaborative filter (avg method): \")\n",
    "    text_file.write(str(mean(l_results_avg)))\n",
    "    text_file.write(\"  -- SD:  \")\n",
    "    text_file.write(str(std(l_results_avg)))\n",
    "    text_file.write(\"\\n\")\n",
    "    text_file.write(\"\\n\")\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## SPECIAL OVERNIGHT CODE\n",
    "\n",
    "# BACKUP DF_SPEND\n",
    "\n",
    "list_neighbourhoods = [20000]\n",
    "\n",
    "for neighbourhood_value in list_neighbourhoods:\n",
    "    n_neighbourhood = neighbourhood_value\n",
    "    \n",
    "    print \"Processing neigbourhood\", neighbourhood_value\n",
    "    \n",
    "    # prepare empty lists to save results \n",
    "    l_results_benchmark_random = []\n",
    "    l_results_benchmark_popularity = []\n",
    "    l_results_sum = []\n",
    "    l_results_avg = []\n",
    "\n",
    "    # For the parameterised # of iterations...\n",
    "    for n_iter in range(1, n_iter_kfold+1):\n",
    "        print \"Processing iteration\", n_iter, \"of\", n_iter_kfold, \"...\"\n",
    "\n",
    "        df_spend = df_spend_master.sample(40000)\n",
    "\n",
    "        # ...run k-fold xvalidation and collate test statistics\n",
    "        k_fold = KFold(len(df_spend), n_folds)     # random_state = 1\n",
    "\n",
    "        for k, (train, test) in enumerate(k_fold):\n",
    "#            print \"                            ... fold\", k+1, \"of\", n_folds\n",
    "\n",
    "            # convert dataframes to numpy arrays (for speed)\n",
    "            ay_train = np.array(df_spend.iloc[train]) #df_train)\n",
    "            ay_test = np.array(df_spend.iloc[test])  # df_test)\n",
    "\n",
    "            # mask one randomly selected merchant from each record in test\n",
    "            masklist = []\n",
    "            for i in ay_test:\n",
    "                indexnonzero = np.flatnonzero(i)\n",
    "                # select one at random and add to a list of indices\n",
    "                indexselect = np.random.choice(indexnonzero)\n",
    "                masklist.append(indexselect)\n",
    "\n",
    "            # mask those merchant entries with 0's\n",
    "            ay_test = ay_test.copy()\n",
    "            ay_test[range(ay_test.shape[0]),masklist]=0  \n",
    "\n",
    "\n",
    "            ##### Benchmark: random #####\n",
    "            # generate recommendations\n",
    "            recmatrix = f_benchmark_random(ay_test)\n",
    "\n",
    "            ## assess accuracy of benchmark recommendations\n",
    "            # 1. drop recommendations for merchants they already shop at\n",
    "            recmatrix[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "            # 2. In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "            top3recs = np.argsort(-recmatrix)[:,:3]   # select top 3 recs for each record\n",
    "            n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "            prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "            l_results_benchmark_random.append(prop_correct_top3)\n",
    "\n",
    "            ##### Benchmark: popularity #####\n",
    "            # generate recommendations\n",
    "            recmatrix = f_benchmark_popularity(ay_train, ay_test)\n",
    "\n",
    "            ## assess accuracy of benchmark recommendations\n",
    "            # 1. drop recommendations for merchants they already shop at\n",
    "            recmatrix[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "            # 2. In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "            top3recs = np.argsort(-recmatrix)[:,:3]   # select top 3 recs for each record\n",
    "            n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "            prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "            l_results_benchmark_popularity.append(prop_correct_top3)\n",
    "\n",
    "            ##### COLLABORATIVE FILTER #####\n",
    "            # generate recommendations for SUM and AVERAGE\n",
    "            recmatrix_sum, recmatrix_avg = f_recommender(ay_train, ay_test, n_neighbourhood)\n",
    "\n",
    "            ## assess accuracy of filter recommendations\n",
    "            # 1. drop recommendations for merchants they already shop at\n",
    "            recmatrix_sum[numpy.where(ay_test==1)]=np.nan\n",
    "            recmatrix_avg[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "            ## Assess accuracy of both sets of recommendations\n",
    "            # 1. for SUM: In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "            top3recs = np.argsort(-recmatrix_sum)[:,:3]   # select top 3 recs for each record\n",
    "            n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "            prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "            l_results_sum.append(prop_correct_top3)\n",
    "\n",
    "            # 2. for AVG: In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "            top3recs = np.argsort(-recmatrix_avg)[:,:3]   # select top 3 recs for each record\n",
    "            n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "            prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "            l_results_avg.append(prop_correct_top3)\n",
    "\n",
    "    ## Print results    \n",
    "    print \"Overall mean results: prop. masked merchants in top 3 recommendations:\"\n",
    "    print \"Benchmark random: \", mean(l_results_benchmark_random)\n",
    "    print \"Benchmark popularity: \", mean(l_results_benchmark_popularity)\n",
    "    print \"Collaborative filter (sum method): \", mean(l_results_sum)\n",
    "    print \"Collaborative filter (avg method): \", mean(l_results_avg)\n",
    "\n",
    "    text_file = open(\"Output.txt\", \"a\")\n",
    "\n",
    "    text_file.write(\"neighourhood: \")\n",
    "    text_file.write(str(n_neighbourhood))\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.write(\"random: \")\n",
    "    text_file.write(str(mean(l_results_benchmark_random)))\n",
    "    text_file.write(\"  -- SD:  \")\n",
    "    text_file.write(str(std(l_results_benchmark_random)))\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.write(\"popularity: \")\n",
    "    text_file.write(str(mean(l_results_benchmark_popularity)))\n",
    "    text_file.write(\"  -- SD:  \")\n",
    "    text_file.write(str(std(l_results_benchmark_popularity)))\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.write(\"Collaborative filter (sum method): \")\n",
    "    text_file.write(str(mean(l_results_sum)))\n",
    "    text_file.write(\"  -- SD:  \")\n",
    "    text_file.write(str(std(l_results_sum)))\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.write(\"Collaborative filter (avg method): \")\n",
    "    text_file.write(str(mean(l_results_avg)))\n",
    "    text_file.write(\"  -- SD:  \")\n",
    "    text_file.write(str(std(l_results_avg)))\n",
    "    text_file.write(\"\\n\")\n",
    "    text_file.write(\"\\n\")\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# set number of iterations of k-Fold to perform\n",
    "n_iter_kfold = 2\n",
    "\n",
    "list_neighbourhoods = [50000]\n",
    "\n",
    "for neighbourhood_value in list_neighbourhoods:\n",
    "    n_neighbourhood = neighbourhood_value\n",
    "    \n",
    "    print \"Processing neigbourhood\", neighbourhood_value\n",
    "    \n",
    "    # prepare empty lists to save results \n",
    "    l_results_benchmark_random = []\n",
    "    l_results_benchmark_popularity = []\n",
    "    l_results_sum = []\n",
    "    l_results_avg = []\n",
    "\n",
    "    # For the parameterised # of iterations...\n",
    "    for n_iter in range(1, n_iter_kfold+1):\n",
    "        print \"Processing iteration\", n_iter, \"of\", n_iter_kfold, \"...\"\n",
    "\n",
    "        df_spend = df_spend_master.sample(80000)\n",
    "\n",
    "        # ...run k-fold xvalidation and collate test statistics\n",
    "        k_fold = KFold(len(df_spend), n_folds)     # random_state = 1\n",
    "\n",
    "        for k, (train, test) in enumerate(k_fold):\n",
    "#            print \"                            ... fold\", k+1, \"of\", n_folds\n",
    "\n",
    "            # convert dataframes to numpy arrays (for speed)\n",
    "            ay_train = np.array(df_spend.iloc[train]) #df_train)\n",
    "            ay_test = np.array(df_spend.iloc[test])  # df_test)\n",
    "\n",
    "            # mask one randomly selected merchant from each record in test\n",
    "            masklist = []\n",
    "            for i in ay_test:\n",
    "                indexnonzero = np.flatnonzero(i)\n",
    "                # select one at random and add to a list of indices\n",
    "                indexselect = np.random.choice(indexnonzero)\n",
    "                masklist.append(indexselect)\n",
    "\n",
    "            # mask those merchant entries with 0's\n",
    "            ay_test = ay_test.copy()\n",
    "            ay_test[range(ay_test.shape[0]),masklist]=0  \n",
    "\n",
    "\n",
    "            ##### Benchmark: random #####\n",
    "            # generate recommendations\n",
    "            recmatrix = f_benchmark_random(ay_test)\n",
    "\n",
    "            ## assess accuracy of benchmark recommendations\n",
    "            # 1. drop recommendations for merchants they already shop at\n",
    "            recmatrix[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "            # 2. In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "            top3recs = np.argsort(-recmatrix)[:,:3]   # select top 3 recs for each record\n",
    "            n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "            prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "            l_results_benchmark_random.append(prop_correct_top3)\n",
    "\n",
    "            ##### Benchmark: popularity #####\n",
    "            # generate recommendations\n",
    "            recmatrix = f_benchmark_popularity(ay_train, ay_test)\n",
    "\n",
    "            ## assess accuracy of benchmark recommendations\n",
    "            # 1. drop recommendations for merchants they already shop at\n",
    "            recmatrix[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "            # 2. In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "            top3recs = np.argsort(-recmatrix)[:,:3]   # select top 3 recs for each record\n",
    "            n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "            prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "            l_results_benchmark_popularity.append(prop_correct_top3)\n",
    "\n",
    "            ##### COLLABORATIVE FILTER #####\n",
    "            # generate recommendations for SUM and AVERAGE\n",
    "            recmatrix_sum, recmatrix_avg = f_recommender(ay_train, ay_test, n_neighbourhood)\n",
    "\n",
    "            ## assess accuracy of filter recommendations\n",
    "            # 1. drop recommendations for merchants they already shop at\n",
    "            recmatrix_sum[numpy.where(ay_test==1)]=np.nan\n",
    "            recmatrix_avg[numpy.where(ay_test==1)]=np.nan\n",
    "\n",
    "            ## Assess accuracy of both sets of recommendations\n",
    "            # 1. for SUM: In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "            top3recs = np.argsort(-recmatrix_sum)[:,:3]   # select top 3 recs for each record\n",
    "            n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "            prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "            l_results_sum.append(prop_correct_top3)\n",
    "\n",
    "            # 2. for AVG: In what % of cases is the masked merchant in the top 3 recommendations?\n",
    "            top3recs = np.argsort(-recmatrix_avg)[:,:3]   # select top 3 recs for each record\n",
    "            n_correct_top3 = sum([masklist[i] in top3recs[i] for i in range(len(masklist))])\n",
    "            prop_correct_top3 = np.true_divide(n_correct_top3, len(ay_test))\n",
    "            l_results_avg.append(prop_correct_top3)\n",
    "\n",
    "    ## Print results    \n",
    "    print \"Overall mean results: prop. masked merchants in top 3 recommendations:\"\n",
    "    print \"Benchmark random: \", mean(l_results_benchmark_random)\n",
    "    print \"Benchmark popularity: \", mean(l_results_benchmark_popularity)\n",
    "    print \"Collaborative filter (sum method): \", mean(l_results_sum)\n",
    "    print \"Collaborative filter (avg method): \", mean(l_results_avg)\n",
    "\n",
    "    text_file = open(\"Output.txt\", \"a\")\n",
    "\n",
    "    text_file.write(\"neighourhood: \")\n",
    "    text_file.write(str(n_neighbourhood))\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.write(\"random: \")\n",
    "    text_file.write(str(mean(l_results_benchmark_random)))\n",
    "    text_file.write(\"  -- SD:  \")\n",
    "    text_file.write(str(std(l_results_benchmark_random)))\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.write(\"popularity: \")\n",
    "    text_file.write(str(mean(l_results_benchmark_popularity)))\n",
    "    text_file.write(\"  -- SD:  \")\n",
    "    text_file.write(str(std(l_results_benchmark_popularity)))\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.write(\"Collaborative filter (sum method): \")\n",
    "    text_file.write(str(mean(l_results_sum)))\n",
    "    text_file.write(\"  -- SD:  \")\n",
    "    text_file.write(str(std(l_results_sum)))\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.write(\"Collaborative filter (avg method): \")\n",
    "    text_file.write(str(mean(l_results_avg)))\n",
    "    text_file.write(\"  -- SD:  \")\n",
    "    text_file.write(str(std(l_results_avg)))\n",
    "    text_file.write(\"\\n\")\n",
    "    text_file.write(\"\\n\")\n",
    "    text_file.write(\"\\n\")\n",
    "\n",
    "    text_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
